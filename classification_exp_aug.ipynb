{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jnVNmf0_UoQZ",
    "outputId": "0d83adba-608d-4551-a2d2-576a4a944311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/makiflow/core/inference/maki_core.py:108: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import (load_data, CLASSIFICATION, REGRESSION, coffe_norm, get_model,\n",
    "                  save_conf_matrix, error_angle, eval_model, get_generator_wrapper)\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import sys\n",
    "from makiflow import set_main_gpu\n",
    "\n",
    "set_main_gpu(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "foLn5zvGVMse"
   },
   "outputs": [],
   "source": [
    "EXP_FOLDER = 'exp_aug'\n",
    "BATCH_SIZE = 64\n",
    "NUM_EXP = 10\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Fxo2li_VkpK",
    "outputId": "912c69ab-0097-43fa-d837-200326ae3429"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [00:00, 553.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1800it [00:02, 610.59it/s]\n",
      "1800it [00:02, 606.75it/s]\n",
      "1800it [00:02, 603.91it/s]\n",
      "1800it [00:02, 635.60it/s]\n",
      "1800it [00:02, 630.68it/s]\n",
      "1800it [00:02, 634.72it/s]\n",
      "1800it [00:02, 623.41it/s]\n",
      "1800it [00:02, 634.85it/s]\n",
      "1800it [00:02, 637.96it/s]\n",
      "1800it [00:02, 639.76it/s]\n",
      "1800it [00:02, 635.51it/s]\n",
      "1800it [00:02, 640.01it/s]\n",
      "1800it [00:02, 650.60it/s]\n",
      "1800it [00:02, 647.63it/s]\n",
      "1800it [00:02, 642.17it/s]\n",
      "1800it [00:02, 651.87it/s]\n",
      "1800it [00:02, 659.53it/s]\n",
      "1800it [00:02, 664.37it/s]\n",
      "1800it [00:02, 674.97it/s]\n",
      "1800it [00:02, 672.27it/s]\n",
      "1800it [00:02, 661.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  30240\n",
      "test:  7560\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/makiflow/layers/untrainable_layers.py:44: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/makiflow/layers/untrainable_layers.py:494: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/makiflow/core/inference/maki_core.py:117: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/makiflow/layers/trainable_layers.py:1052: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/makiflow/core/training/tensorboard.py:41: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "Loss is built.\n",
      "WARNING:tensorflow:From /home/ikilbas/USA/BEAMS/utils/model_tools.py:57: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ikilbas/USA/BEAMS/utils/model_tools.py:58: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "ep:  0\n",
      "Collecting histogram tensors...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/makiflow/core/training/tensorboard.py:61: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/236 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New optimizer is used.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 150/236 [02:13<01:09,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Cross_Entropy: 3.5502663 \n",
      "Training_Loss: 3.5502663 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 236/236 [03:31<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc test:  0.04766949152542373\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/makiflow/core/inference/model_serializer.py:71: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "Weights are saved to exp_aug/0_exp/acc_0.05_ep_0_exp/weights.ckpt\n",
      "Model's architecture is saved to exp_aug/0_exp/acc_0.05_ep_0_exp/model.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/236 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 150/236 [02:09<01:13,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Cross_Entropy: 3.0096975 \n",
      "Training_Loss: 3.0096975 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 236/236 [03:16<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc test:  0.04766949152542373\n",
      "Weights are saved to exp_aug/0_exp/acc_0.05_ep_1_exp/weights.ckpt\n",
      "Model's architecture is saved to exp_aug/0_exp/acc_0.05_ep_1_exp/model.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/236 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 150/236 [02:09<01:19,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Cross_Entropy: 2.1503266 \n",
      "Training_Loss: 2.1503266 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 236/236 [03:24<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc test:  0.1526747881355932\n",
      "Weights are saved to exp_aug/0_exp/acc_0.15_ep_2_exp/weights.ckpt\n",
      "Model's architecture is saved to exp_aug/0_exp/acc_0.15_ep_2_exp/model.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/236 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 150/236 [02:15<01:23,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Cross_Entropy: 1.2051357 \n",
      "Training_Loss: 1.2051357 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 236/236 [03:25<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc test:  0.21808792372881355\n",
      "Weights are saved to exp_aug/0_exp/acc_0.22_ep_3_exp/weights.ckpt\n",
      "Model's architecture is saved to exp_aug/0_exp/acc_0.22_ep_3_exp/model.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/236 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 150/236 [02:01<01:06,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Cross_Entropy: 1.0461409 \n",
      "Training_Loss: 1.0461409 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 236/236 [03:16<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc test:  0.19451800847457626\n",
      "Weights are saved to exp_aug/0_exp/acc_0.19_ep_4_exp/weights.ckpt\n",
      "Model's architecture is saved to exp_aug/0_exp/acc_0.19_ep_4_exp/model.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/236 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 150/236 [02:07<01:27,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Cross_Entropy: 0.9271622 \n",
      "Training_Loss: 0.9271622 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 213/236 [03:00<00:21,  1.09it/s]"
     ]
    }
   ],
   "source": [
    "for n_exp in range(NUM_EXP):\n",
    "    # Create folder with `n_exp`-th num experminet\n",
    "    path_to_exp = os.path.join(EXP_FOLDER, f'{n_exp}_exp')\n",
    "    os.makedirs(path_to_exp, exist_ok=True)\n",
    "    \n",
    "    # At start of each experiments - create new dataset (shuffle it)\n",
    "    Xtrain, Ytrain, Xtest, Ytest, pred2params, config_data = load_data(\n",
    "        path_exp_folder=path_to_exp,\n",
    "        path_to_data='expand_double_modes',\n",
    "        use_saved=False,\n",
    "        size_hw=(336, 336),\n",
    "        test_div=0.8,\n",
    "        data_type=CLASSIFICATION,\n",
    "    )\n",
    "\n",
    "    Ytrain = np.array(Ytrain).astype(np.int32)\n",
    "    Ytest = np.array(Ytest).astype(np.int32)\n",
    "    \n",
    "    # Create model\n",
    "    model, trainer, opt, global_step, sess = get_model(size_hw=(336, 336), batch_size=BATCH_SIZE, size_dataset=len(Ytrain))\n",
    "    gen = get_generator_wrapper(Xtrain, Ytrain, BATCH_SIZE)\n",
    "    accur_list = []\n",
    "\n",
    "    for epoch_num in range(EPOCHS):\n",
    "        # Each epoch:\n",
    "        # Train -> eval -> create folder -> save weights/arch -> save results\n",
    "        print('ep: ', epoch_num)\n",
    "        info1 = trainer.fit_generator(\n",
    "            gen, optimizer=opt, epochs=1, \n",
    "            iter=len(Xtrain)//(2*BATCH_SIZE), print_period=150, global_step=global_step\n",
    "        )\n",
    "        acc_test, predictions = eval_model(model, Xtest, Ytest, BATCH_SIZE, calc_mean=False)\n",
    "        acc_float = np.mean(acc_test)\n",
    "        print('acc test: ', acc_float)\n",
    "        accur_list.append(acc_float)\n",
    "        \n",
    "        # Create folder\n",
    "        path_to_s_epoch = os.path.join(path_to_exp, f'acc_{round(acc_float, 2)}_ep_{epoch_num}_exp')\n",
    "        os.makedirs(path_to_s_epoch, exist_ok=True)\n",
    "        # Save weights/arch\n",
    "        model.save_weights(os.path.join(path_to_s_epoch, 'weights.ckpt'))\n",
    "        model.save_architecture(os.path.join(path_to_s_epoch, 'model.json'))\n",
    "        # Save results\n",
    "        save_conf_matrix(Ytest, predictions, os.path.join(path_to_s_epoch, 'conf_matrix.png'))\n",
    "        error_angle(\n",
    "            os.path.join(path_to_s_epoch, 'error_angle_all_class.png'), \n",
    "            config_data, Ytest, predictions\n",
    "        )\n",
    "        error_angle(\n",
    "            os.path.join(path_to_s_epoch, 'error_angle_20_19_classes.png'), \n",
    "            config_data, Ytest, predictions, class_find=[20, 19]\n",
    "        )\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.plot(accur_list)\n",
    "    fig.savefig(os.path.join(path_to_exp, 'acc.png'))\n",
    "    # Clear plt figures\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Xtest[-100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest[-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
