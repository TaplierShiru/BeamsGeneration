{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jnVNmf0_UoQZ",
    "outputId": "0d83adba-608d-4551-a2d2-576a4a944311"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from makizoo.backbones.resnetv1 import ResNet18\n",
    "from makizoo.backbones.mobilenetv2 import MobileNetV2_1_4, MobileNetV2_1_0, MobileNetV2_0_75\n",
    "from makiflow.layers import *\n",
    "from makiflow.models.regressor import Regressor, AbsTrainer, MseTrainer\n",
    "from makiflow.generators.classification import cycle_generator\n",
    "\n",
    "from makiflow import set_main_gpu\n",
    "\n",
    "set_main_gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Fxo2li_VkpK",
    "outputId": "912c69ab-0097-43fa-d837-200326ae3429"
   },
   "outputs": [],
   "source": [
    "config_data = {'train': [], 'test': []}\n",
    "path_exp = 'weights_regres'\n",
    "\n",
    "SIZE_HW = (336, 336)\n",
    "\n",
    "path_to_data = 'expand_double_modes' #'/content/drive/MyDrive/Neural network/work/beams/data'\n",
    "folders_path = sorted(glob(path_to_data + '/*'), key=lambda x: float(x.split('/')[-1]))\n",
    "Xtrain = []\n",
    "Xtest = []\n",
    "\n",
    "Ytrain = []\n",
    "Ytest = []\n",
    "pred2param = {}\n",
    "\n",
    "test_div = 0.8\n",
    "print(len(folders_path))\n",
    "for i, single_folder in enumerate(folders_path):\n",
    "    # Single folder - 1 class\n",
    "    path_images = shuffle(glob(single_folder + '/*'))\n",
    "    num_class = float(single_folder.split('/')[-1])\n",
    "    size = len(path_images)\n",
    "    iterator = tqdm(enumerate(path_images))\n",
    "    for j, single_img_path in iterator:\n",
    "        readed_img = cv2.resize(cv2.imread(single_img_path)[..., ::-1], SIZE_HW)\n",
    "        if int(size * test_div) > j:\n",
    "            # train\n",
    "            Xtrain.append(readed_img)\n",
    "            Ytrain.append(num_class)\n",
    "            config_data['train'] += [single_img_path.split('/')[-1]]\n",
    "        else:\n",
    "            # test\n",
    "            Xtest.append(readed_img)\n",
    "            Ytest.append(num_class)\n",
    "            config_data['test'] += [single_img_path.split('/')[-1]]\n",
    "    iterator.close()\n",
    "\n",
    "with open(f'{path_exp}/config_train_test.json', 'w') as fp:\n",
    "    json.dump(config_data, fp)\n",
    "    \n",
    "print('train : ', len(Ytrain))\n",
    "print('test: ', len(Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6aMIeScKh6r4"
   },
   "outputs": [],
   "source": [
    "coffe_norm = lambda x: (x - 128.0) / 128.0\n",
    "\n",
    "#Xtrain = coffe_norm(np.array(Xtrain)).astype(np.float32)\n",
    "#Xtest = coffe_norm(np.array(Xtest)).astype(np.float32)\n",
    "\n",
    "Ytrain = np.array(Ytrain).astype(np.float32)\n",
    "Ytest = np.array(Ytest).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "l7-NpaZIVkvH",
    "outputId": "36f56f8c-6ba8-4513-ac37-b5f7b5a64dc3"
   },
   "outputs": [],
   "source": [
    "plt.imshow(Xtrain[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foLn5zvGVMse"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9g_skJwVMu3"
   },
   "outputs": [],
   "source": [
    "id_num = 0\n",
    "def block(x, in_f, out_f):\n",
    "    global id_num\n",
    "    \n",
    "    id = id_num\n",
    "    SX = x\n",
    "    FX = x\n",
    "    \n",
    "    FX = ConvLayer(kw=3, kh=3, in_f=in_f, out_f=out_f, name=f'conv_main_{id}_1', activation=None)(FX)\n",
    "    FX = BatchNormLayer(D=out_f, name=f'bn_main_{id}_1')(FX)\n",
    "    FX = ActivationLayer(name=f'act_1_{id}')(FX)\n",
    "    \n",
    "    FX = ConvLayer(kw=3, kh=3, in_f=out_f, out_f=out_f, name=f'conv_main_{id}_2', activation=None)(FX)\n",
    "    FX = BatchNormLayer(D=out_f, name=f'bn_main_{id}_2')(FX)\n",
    "    FX = ActivationLayer(name=f'act_2_{id}')(FX)\n",
    "    \n",
    "    if in_f != out_f:\n",
    "        SX = BatchNormLayer(D=in_f, name=f'bn_skip_{id}_1')(SX)\n",
    "        SX = ConvLayer(kw=1, kh=1, in_f=in_f, out_f=out_f, name=f'conv_skip_{id}', activation=None)(SX)\n",
    "    \n",
    "    x_sum = SumLayer(name=f'sum_{id}')([FX, SX])\n",
    "    id_num += 1\n",
    "    return x_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mQTY6vTsVRal",
    "outputId": "63f15c6f-7992-400b-ae04-0a820f97d77e"
   },
   "outputs": [],
   "source": [
    "custom_backbone = False\n",
    "\n",
    "if custom_backbone:\n",
    "    inp = InputLayer(input_shape=[None, SIZE_HW[0], SIZE_HW[1], 3], name='input')\n",
    "    x = block(inp, in_f=3, out_f=64)\n",
    "    x = MaxPoolLayer(name='mp1')(x)\n",
    "    # 168\n",
    "    x = block(x, in_f=64, out_f=128)\n",
    "    x = block(x, in_f=128, out_f=128)\n",
    "    x = MaxPoolLayer(name='mp2')(x)\n",
    "    # 84\n",
    "    x = block(x, in_f=128, out_f=128)\n",
    "    x = block(x, in_f=128, out_f=128)\n",
    "    x = MaxPoolLayer(name='mp3')(x)\n",
    "    # 42\n",
    "    x = block(x, in_f=128, out_f=256)\n",
    "    x = block(x, in_f=256, out_f=256)\n",
    "    x = MaxPoolLayer(name='mp4')(x)\n",
    "    # 21\n",
    "    x = block(x, in_f=256, out_f=512)\n",
    "    x = block(x, in_f=512, out_f=512)\n",
    "    #x = MaxPoolLayer(name='mp5')(x)\n",
    "    # 10\n",
    "else:\n",
    "    inp, x = ResNet18([BATCH_SIZE, SIZE_HW[0], SIZE_HW[1], 3])\n",
    "\n",
    "x = GlobalAvgPoolLayer('flat')(x)\n",
    "x = DropoutLayer(name='drop_final', p_keep=0.7)(x)\n",
    "x = DenseLayer(in_d=x.get_shape()[-1], out_d=1, use_bias=False, activation=None, name='regression_out')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-H9OyPaYVMw6",
    "outputId": "b8740e32-a83f-475f-99d3-e2fef426aed2"
   },
   "outputs": [],
   "source": [
    "model = Regressor([inp], [x], name='MakiResNet')\n",
    "sess = tf.Session()\n",
    "model.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l-7q57nOVMy3"
   },
   "outputs": [],
   "source": [
    "trainer = MseTrainer(model, [inp])\n",
    "trainer.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0077tq_OkeQZ",
    "outputId": "76279e58-83bb-4aee-acf7-aef0d04dcca8"
   },
   "outputs": [],
   "source": [
    "len(Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, dtype=tf.int32)\n",
    "lr = tf.train.exponential_decay(5e-3, global_step, decay_steps=(len(Ytrain) // BATCH_SIZE) * 2, decay_rate=0.92)\n",
    "opt = tf.train.AdamOptimizer(lr)\n",
    "sess.run(tf.variables_initializer([global_step]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_wrapper(gen_data, *args):\n",
    "    while True:\n",
    "        X_data, Y_data = next(gen_data)\n",
    "        X_data = X_data[0]\n",
    "        Y_data = Y_data[0]\n",
    "        \"\"\"\n",
    "        rotate_angle = np.random.uniform(-90, 90, size=(len(X_data))).astype(np.float32)\n",
    "        #X_data = [ndimage.rotate(X_data[i], rotate_angle[i], reshape=False) for i in range(len(X_data))]\n",
    "        X_data = [\n",
    "            np.array(\n",
    "                Image.fromarray(X_data[i]).rotate(rotate_angle[i], resample=Image.BICUBIC).getdata()\n",
    "            ).reshape(SIZE_HW[0], SIZE_HW[1], 3)\n",
    "            for i in range(len(X_data))\n",
    "        ]\n",
    "        \n",
    "        ra = random.random()\n",
    "        type_rotate = None\n",
    "        \n",
    "        if ra > 0.3 and ra < 0.5:\n",
    "            type_rotate = cv2.ROTATE_180\n",
    "        elif ra > 0.5 and ra < 0.7:\n",
    "            type_rotate = cv2.ROTATE_90_CLOCKWISE\n",
    "        elif ra > 0.7:\n",
    "            type_rotate = cv2.ROTATE_90_COUNTERCLOCKWISE\n",
    "        \n",
    "        if type_rotate is not None:\n",
    "            X_data = [cv2.rotate(X_data[i], type_rotate) for i in range(len(X_data))]\n",
    "        \"\"\"\n",
    "        #if random.random() > 0.6:\n",
    "        #    X_data = [gaussian_filter(X_data[i], sigma=1.5) for i in range(len(X_data))]\n",
    "        \n",
    "        X_data = coffe_norm(np.asarray(X_data)).astype(np.float32, copy=False)\n",
    "        \n",
    "        yield (X_data,), (Y_data, )\n",
    "\n",
    "\n",
    "gen = generator_wrapper(cycle_generator(Xtrain, Ytrain.reshape(-1, 1), BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = next(gen)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(xxx[0][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_common_l2_weight_decay(1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def predict(data_pr):\n",
    "    output_mf = x\n",
    "    ans = [\n",
    "        output_mf.eval(feed_dict={inp: data_pr[i*BATCH_SIZE:(i+1)*BATCH_SIZE]}, sess=sess) \n",
    "        for i in range(len(data_pr)//BATCH_SIZE)\n",
    "    ]\n",
    "    ans = np.concatenate(ans, axis=0).reshape(-1)\n",
    "    \n",
    "    return ans.astype(np.float32, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fk6UiHyoVXF2",
    "outputId": "ac5d9100-22d8-4353-dbdc-8a72435dbfb3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "abs_mean_list = []\n",
    "\n",
    "for _ in range(20):\n",
    "    info1 = trainer.fit_generator(\n",
    "        gen, optimizer=opt, epochs=1, \n",
    "        iter=len(Xtrain)//(2*BATCH_SIZE), print_period=150, global_step=global_step\n",
    "    )\n",
    "    \n",
    "    predictions = predict(coffe_norm(np.array(Xtest)))\n",
    "    predictions_train = predict(coffe_norm(np.array(Xtrain)))\n",
    "    \n",
    "    acc_float = np.mean(np.power(predictions - Ytest[:len(predictions)].reshape(-1), 2))\n",
    "    print('acc test: ', acc_float)\n",
    "    print('mean pred: ', predictions.mean())\n",
    "    print('--------------')\n",
    "    print('mse loss: ', np.mean((predictions_train - Ytrain[:len(predictions_train)].reshape(-1)) ** 2))\n",
    "    print('mean pred train: ', predictions_train.mean())\n",
    "    print('train pred: ', predictions_train)\n",
    "    \n",
    "    abs_mean_list.append(acc_float)\n",
    "    print('pred: ', predictions[BATCH_SIZE:].reshape(-1))\n",
    "    print('labels: ', Ytest[BATCH_SIZE:].reshape(-1))\n",
    "    \n",
    "    #predictions = model.predict(coffe_norm(np.array(Xtrain)))\n",
    "    #predictions = np.argmax(predictions, axis=-1)\n",
    "    #print('acc train: ', np.mean(predictions == Ytrain.reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXXex0F-VXIA",
    "outputId": "effab6f8-0257-4ec8-b781-dc11b0e37880",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predictions = [\n",
    "#    model.predict(\n",
    "#        coffe_norm(np.array(Xtest)[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
    "#    ) \n",
    "#    for i in [len(Xtest)//BATCH_SIZE-1] #range(len(Xtest)//BATCH_SIZE)\n",
    "#]\n",
    "predictions = predict(Xtest)\n",
    "#predictions = np.concatenate(predictions, axis=0).reshape(-1)\n",
    "acc_float = np.mean(np.power(predictions - Ytest[:len(predictions)].reshape(-1), 2))\n",
    "print('acc test: ', acc_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions[6000:].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest[3000:3100].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "pGnQnMW8Vhcg",
    "outputId": "54126704-d491-443a-cdb2-cbe2b92b1f91"
   },
   "outputs": [],
   "source": [
    "plt.plot(info1[trainer.TRAINING_LOSS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "af0QFbOKVher"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(coffe_norm(np.array(Xtrain)))\n",
    "predictions = np.argmax(predictions, axis=-1)\n",
    "print(np.mean(predictions == Ytrain.reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_mf = model.get_node('flat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = [output_mf.eval(feed_dict={inp: Xtest[i*BATCH_SIZE:(i+1)*BATCH_SIZE]}, sess=sess) for i in range(len(Xtest)//BATCH_SIZE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = np.concatenate(ans, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "reduced = pca.fit_transform(ans)\n",
    "plt.scatter(reduced[:,0],reduced[:,1] ,s=100,c=Ytest[:ans.shape[0]],alpha=0.5)\n",
    "plt.savefig('pca.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE()\n",
    "Z = tsne.fit_transform(ans)\n",
    "plt.scatter(Z[:,0],Z[:,1] ,s=100,c=Ytest[:ans.shape[0]],alpha=0.5)\n",
    "plt.savefig('tsne.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
